{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdc62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd60c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = (Path.cwd() / \"..\" / \"..\").resolve()\n",
    "DATA_PATH = PROJECT_ROOT / \"datasets\"\n",
    "ORIGINAL_DATA = DATA_PATH / \"raw\" / \"images\"\n",
    "PROCESSED_DATA = DATA_PATH / \"processed\" / \"images\"\n",
    "# Rutas específicas\n",
    "TRAIN_IMAGES = ORIGINAL_DATA / \"train\"\n",
    "TEST_IMAGES = ORIGINAL_DATA / \"test\"\n",
    "CSV_PATH = ORIGINAL_DATA / \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5518f056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: C:\\Users\\Sebastian\\Desktop\\MachineLearningPC2\\TF_Machine_Learning_1888\\datasets\n",
      "Raw images: C:\\Users\\Sebastian\\Desktop\\MachineLearningPC2\\TF_Machine_Learning_1888\\datasets\\raw\\images\n",
      "Processed: C:\\Users\\Sebastian\\Desktop\\MachineLearningPC2\\TF_Machine_Learning_1888\\datasets\\processed\\images\n",
      "Clases: ['Nodule/Mass', 'Other lesion']\n"
     ]
    }
   ],
   "source": [
    "CANCER_CLASSES = [\"Nodule/Mass\", \"Other lesion\"]\n",
    "CLASS_MAPPING = {class_name: idx for idx, class_name in enumerate(CANCER_CLASSES)}\n",
    "print(f\"Dataset: {DATA_PATH}\")\n",
    "print(f\"Raw images: {ORIGINAL_DATA}\")\n",
    "print(f\"Processed: {PROCESSED_DATA}\")\n",
    "print(f\"Clases: {CANCER_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc1769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros: 67,914\n",
      "Imágenes únicas: 15,000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>rad_id</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>raw_x_min</th>\n",
       "      <th>raw_x_max</th>\n",
       "      <th>raw_y_min</th>\n",
       "      <th>raw_y_max</th>\n",
       "      <th>raw_width</th>\n",
       "      <th>raw_height</th>\n",
       "      <th>scale_x</th>\n",
       "      <th>scale_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78aa8415fbf1c792f7d7c53349d44d4f</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.341333</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78aa8415fbf1c792f7d7c53349d44d4f</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.341333</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78aa8415fbf1c792f7d7c53349d44d4f</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.341333</td>\n",
       "      <td>0.341333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>183015e171f5159d7e60d43578632a3f</td>\n",
       "      <td>Aortic enlargement</td>\n",
       "      <td>0</td>\n",
       "      <td>R8</td>\n",
       "      <td>567.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>183015e171f5159d7e60d43578632a3f</td>\n",
       "      <td>Pleural thickening</td>\n",
       "      <td>11</td>\n",
       "      <td>R9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.409600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          image_id          class_name  class_id  \\\n",
       "0           0  78aa8415fbf1c792f7d7c53349d44d4f          No finding        14   \n",
       "1           1  78aa8415fbf1c792f7d7c53349d44d4f          No finding        14   \n",
       "2           2  78aa8415fbf1c792f7d7c53349d44d4f          No finding        14   \n",
       "3           3  183015e171f5159d7e60d43578632a3f  Aortic enlargement         0   \n",
       "4           4  183015e171f5159d7e60d43578632a3f  Pleural thickening        11   \n",
       "\n",
       "  rad_id  x_min  y_min  x_max  y_max  raw_x_min  raw_x_max  raw_y_min  \\\n",
       "0    R16    NaN    NaN    NaN    NaN        NaN        NaN        NaN   \n",
       "1    R17    NaN    NaN    NaN    NaN        NaN        NaN        NaN   \n",
       "2    R11    NaN    NaN    NaN    NaN        NaN        NaN        NaN   \n",
       "3     R8  567.0  295.0  671.0  417.0     1134.0     1342.0      721.0   \n",
       "4     R9   58.0  794.0  116.0  851.0      117.0      232.0     1938.0   \n",
       "\n",
       "   raw_y_max  raw_width  raw_height   scale_x   scale_y  \n",
       "0        NaN     3000.0      3000.0  0.341333  0.341333  \n",
       "1        NaN     3000.0      3000.0  0.341333  0.341333  \n",
       "2        NaN     3000.0      3000.0  0.341333  0.341333  \n",
       "3     1019.0     2048.0      2500.0  0.500000  0.409600  \n",
       "4     2077.0     2048.0      2500.0  0.500000  0.409600  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Total registros: {len(df):,}\")\n",
    "print(f\"Imágenes únicas: {df['image_id'].nunique():,}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbcf9cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros cáncer: 4,783\n",
      "Imágenes cáncer: 1,632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "Nodule/Mass     2580\n",
       "Other lesion    2203\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = df[df['class_name'].isin(CANCER_CLASSES)].copy()\n",
    "cancer_df = cancer_df.dropna(subset=['x_min', 'y_min', 'x_max', 'y_max'])\n",
    "cancer_df['class_id'] = cancer_df['class_name'].map(CLASS_MAPPING)\n",
    "\n",
    "print(f\"Registros cáncer: {len(cancer_df):,}\")\n",
    "print(f\"Imágenes cáncer: {cancer_df['image_id'].nunique():,}\")\n",
    "cancer_df['class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc9eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros cáncer: 4,783\n",
      "Imágenes cáncer: 1,632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "Nodule/Mass     2580\n",
       "Other lesion    2203\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = df[df['class_name'].isin(CANCER_CLASSES)].copy()\n",
    "cancer_df = cancer_df.dropna(subset=['x_min', 'y_min', 'x_max', 'y_max'])\n",
    "cancer_df['class_id'] = cancer_df['class_name'].map(CLASS_MAPPING)\n",
    "\n",
    "print(f\"Registros cáncer: {len(cancer_df):,}\")\n",
    "print(f\"Imágenes cáncer: {cancer_df['image_id'].nunique():,}\")\n",
    "\n",
    "# Distribución por clase\n",
    "cancer_df['class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7f9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en train: 15000\n",
      "Archivos en test: 3000\n",
      "Imágenes en CSV: 1632\n",
      "Coincidencias train: 1632\n",
      "Coincidencias test: 0\n",
      "Train: 1,632 imágenes\n",
      "Test: 0 imágenes\n"
     ]
    }
   ],
   "source": [
    "train_images = set([f.stem for f in TRAIN_IMAGES.glob(\"*.jpg\") if f.is_file()])\n",
    "test_images = set([f.stem for f in TEST_IMAGES.glob(\"*.jpg\") if f.is_file()])\n",
    "\n",
    "print(f\"Archivos en train: {len(train_images)}\")\n",
    "print(f\"Archivos en test: {len(test_images)}\")\n",
    "\n",
    "# Ver nombres en CSV\n",
    "csv_images = set(cancer_df['image_id'].unique())\n",
    "print(f\"Imágenes en CSV: {len(csv_images)}\")\n",
    "\n",
    "# Verificar coincidencias\n",
    "train_matches = train_images.intersection(csv_images)\n",
    "test_matches = test_images.intersection(csv_images)\n",
    "\n",
    "print(f\"Coincidencias train: {len(train_matches)}\")\n",
    "print(f\"Coincidencias test: {len(test_matches)}\")\n",
    "\n",
    "train_cancer = cancer_df[cancer_df['image_id'].isin(train_images)].copy()\n",
    "test_cancer = cancer_df[cancer_df['image_id'].isin(test_images)].copy()\n",
    "\n",
    "print(f\"Train: {train_cancer['image_id'].nunique():,} imágenes\")\n",
    "print(f\"Test: {test_cancer['image_id'].nunique():,} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ff6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train final: 1,468 imágenes (4,341 anotaciones)\n",
      "Val final: 164 imágenes (442 anotaciones)\n",
      "\n",
      "Train:\n",
      "class_name\n",
      "Nodule/Mass     2349\n",
      "Other lesion    1992\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val:\n",
      "class_name\n",
      "Nodule/Mass     231\n",
      "Other lesion    211\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_train_images = train_cancer['image_id'].unique()\n",
    "\n",
    "# 90% train, 10% val\n",
    "train_imgs, val_imgs = train_test_split(unique_train_images, test_size=0.1, random_state=42)\n",
    "\n",
    "train_final = train_cancer[train_cancer['image_id'].isin(train_imgs)].copy()\n",
    "val_final = train_cancer[train_cancer['image_id'].isin(val_imgs)].copy()\n",
    "\n",
    "print(f\"Train final: {train_final['image_id'].nunique():,} imágenes ({len(train_final):,} anotaciones)\")\n",
    "print(f\"Val final: {val_final['image_id'].nunique():,} imágenes ({len(val_final):,} anotaciones)\")\n",
    "\n",
    "# Verificar distribución por clase en cada split\n",
    "for split_name, split_df in [('Train', train_final), ('Val', val_final)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(split_df['class_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68de820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_yolo(df, img_w=1024, img_h=1024):\n",
    "    \"\"\"Convertir coordenadas a formato YOLO\"\"\"\n",
    "    df = df.copy()\n",
    "    df['x_center'] = ((df['x_min'] + df['x_max']) / 2) / img_w\n",
    "    df['y_center'] = ((df['y_min'] + df['y_max']) / 2) / img_h\n",
    "    df['width'] = (df['x_max'] - df['x_min']) / img_w\n",
    "    df['height'] = (df['y_max'] - df['y_min']) / img_h\n",
    "    \n",
    "    for coord in ['x_center', 'y_center', 'width', 'height']:\n",
    "        df[coord] = df[coord].clip(0, 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yolo_labels(df, split_name):\n",
    "    \"\"\"Guardar labels en formato YOLO (.txt)\"\"\"\n",
    "    labels_path = PROCESSED_DATA / split_name / \"labels\"\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    saved_files = 0\n",
    "    for image_id, group in df.groupby('image_id'):\n",
    "        label_file = labels_path / f\"{image_id}.txt\"\n",
    "        \n",
    "        with open(label_file, 'w') as f:\n",
    "            for _, row in group.iterrows():\n",
    "                f.write(f\"{int(row['class_id'])} {row['x_center']:.6f} {row['y_center']:.6f} \"\n",
    "                       f\"{row['width']:.6f} {row['height']:.6f}\\n\")\n",
    "        saved_files += 1\n",
    "    \n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df550956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Coordenadas convertidas a YOLO\n"
     ]
    }
   ],
   "source": [
    "def copy_images_split(df, split_name):\n",
    "    \"\"\"Copiar imágenes del split\"\"\"\n",
    "    source_path = TRAIN_IMAGES  # Todas vienen de train\n",
    "    target_path = PROCESSED_DATA / split_name / \"images\"\n",
    "    target_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    copied = 0\n",
    "    for image_id in df['image_id'].unique():\n",
    "        source_file = source_path / f\"{image_id}.jpg\"\n",
    "        target_file = target_path / f\"{image_id}.jpg\"\n",
    "        \n",
    "        if source_file.exists():\n",
    "            shutil.copy2(source_file, target_file)\n",
    "            copied += 1\n",
    "    \n",
    "    return copied\n",
    "\n",
    "# Convertir a YOLO\n",
    "train_yolo = to_yolo(train_final)\n",
    "val_yolo = to_yolo(val_final)\n",
    "\n",
    "print(\"✅ Coordenadas convertidas a YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0fe7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Labels guardados:\n",
      "  Train: 1468 archivos .txt\n",
      "  Val: 164 archivos .txt\n"
     ]
    }
   ],
   "source": [
    "# Guardar labels .txt\n",
    "train_labels = save_yolo_labels(train_yolo, 'train')\n",
    "val_labels = save_yolo_labels(val_yolo, 'val')\n",
    "\n",
    "print(f\"📄 Labels guardados:\")\n",
    "print(f\"  Train: {train_labels} archivos .txt\")\n",
    "print(f\"  Val: {val_labels} archivos .txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07511741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Imágenes copiadas:\n",
      "  Train: 1468 imágenes\n",
      "  Val: 164 imágenes\n"
     ]
    }
   ],
   "source": [
    "train_copied = copy_images_split(train_yolo, 'train')\n",
    "val_copied = copy_images_split(val_yolo, 'val')\n",
    "\n",
    "print(f\"📁 Imágenes copiadas:\")\n",
    "print(f\"  Train: {train_copied} imágenes\")\n",
    "print(f\"  Val: {val_copied} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be37f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Dataset YAML creado: C:\\Users\\Sebastian\\Desktop\\MachineLearningPC2\\TF_Machine_Learning_1888\\datasets\\processed\\images\\dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "dataset_config = {\n",
    "    'path': str(PROCESSED_DATA),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'nc': len(CANCER_CLASSES),\n",
    "    'names': CANCER_CLASSES\n",
    "}\n",
    "yaml_path = PROCESSED_DATA / \"dataset.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"⚙️ Dataset YAML creado: {yaml_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
